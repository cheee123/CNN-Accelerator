# An Energy-Efficient CNN Accelerator Specialized for PYNQ-Z2 FPGA Device

Link to full Vivado Project:

https://drive.google.com/file/d/1IN2Pbm-QDITSB-fZIZx7LSp09HazjuFS/view?usp=sharing

## Introduction

The aim of this study is to build a low power CNN accelerator specialized for PYNQ-Z2.

The employed CNN model is to classify the gender based on input face images.

Based on the model architecture, we construct all the layers by pure logical circuits.

The system is completed from software to hardware to real-time application.



<img src=ImagesForREADME/SystemArchitecture.png width="480">

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; System architecture

## Objective:

1. To deploy a software-based model into a hardware circuits

2. To leverage the virtue of quantization

3. To make data available for hardware implementation

4. To design the hardware architecture for CNN layers

5. To realize the communication between heterogeneous systems.

6. To validate the correctness of the design

7. To turn a complete hard-software system into a real-time application

## Hardware architecture

<img align="mid" src=ImagesForREADME/PL_Architecture.png width="360">

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PL Architecture

### Convolution

Convolution is built based on the Eyeriss architecture to achieve best efficiency.

Efficient partial sum (psum) accumulation and minimizing data movement become essential to conserve storage space and memory read/write energy. However, achieving maximum input data reuse while immediately reducing psums is challenging, as psums generated by Multiply and Accumulate (MAC) operations using the same filter or ifmap value are not readily reducible.

Our strategy is to complete the psum of the output feature map at the earliest possible, also leverage synchronous computing to balance the reuse ratio and storage resources.

### Maxpooling

Maxpooling is implemented in a simple SISO style. The first two rows of activation are streamed in sequentially, a signed fixed point comparator are employed between a 2x2 component, the largest number is then streamed out and written in a BRAM.

### Fully Connected Layers

The first layer of Fully Connected Layers requires the most computation resources and memory cost. It is not possible to load every feature map and weight into the chip and perform cross-multiplication at the same time. To balance the hardware requirement between layers, we apply partial sum strategy, which load a small amount of data every stage and accumulate the multiplication result. For the last two layers, we reuse the same hardware and can infer each output node immediately without any accumulation.

## Result

The implemented architecture on the PYNQ-Z2 development board has undergone synthesis, yielding the following resource utilization metrics:

Slice LUTs at 41%, Slice Registers at 17%, Block RAM at 30%, and DSP at 25%

A maximum clock frequency of 50MHz was achieved, successfully meeting the specified timing constraints.

The obtained results indicate that the total inference time for a single frame is 267,000 cycles, which is equivalent to 0.5ms.

<img align="mid" src=ImagesForREADME/Utilization.png width="1060">

<img align="mid" src=ImagesForREADME/TimingReport.png width="1060">

## References

Chen, Yu-Hsin, et al. "Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks." IEEE journal of solid-state circuits 52.1 (2016): 127-138.
